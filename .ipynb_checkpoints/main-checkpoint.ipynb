{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fdf3e6-ebb0-4753-9044-0b4714ab7ba7",
   "metadata": {},
   "source": [
    "# Spam Email Detection\n",
    "\n",
    "This project implements a machine learning pipeline to classify emails as spam or not spam using natural language processing and various classification algorithms. The dataset is preprocessed to clean text data, vectorized, and then used to train multiple models to determine the most effective classifier.\n",
    "\n",
    "## Features\n",
    "- Data cleaning (removing punctuation, stop words, stemming).\n",
    "- Splitting the data into training and test sets.\n",
    "- Testing multiple machine learning classifiers:\n",
    "  - Logistic Regression\n",
    "  - Decision Tree\n",
    "  - Random Forest\n",
    "  - Gradient Boosting\n",
    "  - Support Vector Classifier\n",
    "  - K-Nearest Neighbors\n",
    "  - Naive Bayes\n",
    "- Performance evaluation using metrics like accuracy, confusion matrix, and classification report.\n",
    "\n",
    "## Dataset\n",
    "The project uses the [Spam Mails Dataset], which contains labeled email messages with labels `0` (not spam) and `1` (spam).\n",
    "\n",
    "## Installation\n",
    "\n",
    "1. Clone the repository or download the script file:\n",
    "   ```bash\n",
    "   git clone <repository_url>\n",
    "   ```\n",
    "2. Install the required libraries:\n",
    "   ```bash\n",
    "   pip install numpy pandas matplotlib seaborn scikit-learn xgboost nltk\n",
    "   ```\n",
    "\n",
    "3. Download the dataset and place it in the appropriate directory as specified in the script.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Run the script to preprocess the data and train the models:\n",
    "   ```bash\n",
    "   python spam_email_detection.py\n",
    "   ```\n",
    "2. Review the outputs to determine the performance of various classifiers. The best-performing model can be selected for further use or deployment.\n",
    "\n",
    "## Results\n",
    "\n",
    "- Random Forest achieved the highest accuracy of **97.64%** on the test dataset.\n",
    "- Confusion matrices and classification reports for all models are displayed in the output.\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    "- Fine-tuning hyperparameters to improve model accuracy.\n",
    "- Testing additional text vectorization techniques like TF-IDF.\n",
    "- Integrating the model into a real-time spam detection application.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Python 3.7+\n",
    "- Libraries:\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "  - seaborn\n",
    "  - scikit-learn\n",
    "  - xgboost\n",
    "  - nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044d690-2d08-457c-8e7f-044528a0a909",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b0ac0-950d-43a3-9d9d-e178954391f0",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7499f4d-c966-450e-b1c5-f0db9f83550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv(\"spam_ham_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de6e35-74fa-4dbb-8850-18c4ee3c8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9bece-a6e7-4fd9-970f-750957a6ad5f",
   "metadata": {},
   "source": [
    "# Data Preprocesssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdb4ae-dc53-4adb-b4a3-73e3eccffe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c94a99-7dcd-4ccd-87fa-cefccf283200",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790e9db-951d-434c-aa19-9dd8e84c359f",
   "metadata": {},
   "source": [
    "* so we have no null and duplicate value\n",
    "* we only need text and label num for our purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4d19e-53f0-4589-a768-924b91c96214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= dataset[[\"text\",\"label_num\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1c6c3-e719-4e64-9202-fdf7ee83fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len(df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f9504-d986-4567-bb02-87bf696b9b56",
   "metadata": {},
   "source": [
    "# Cleaning text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e9ddd-cf22-4a3f-837d-7f74865e9cd8",
   "metadata": {},
   "source": [
    "* We will remove punctuation and other unnecessary item from our text\n",
    "* Then will be stemming the word to its root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2406da-ef31-4140-9941-83a45b1289ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpus= []\n",
    "# contain list of words that will be used for training -> final words after cleaning\n",
    "\n",
    "for i in range(0,length):\n",
    "    # re is used to remove punctuation\n",
    "    text= re.sub('[^a-zA-Z]',' ',df[\"text\"][i])\n",
    "\n",
    "    # converting to lower case\n",
    "    text=text.lower()\n",
    "\n",
    "    #stemming\n",
    "    text=text.split()\n",
    "    ps= PorterStemmer()\n",
    "    all_stopwords= stopwords.words(\"english\")\n",
    "    text= [ps.stem(word) for word in text if not word in set(all_stopwords)]\n",
    "    text= ' '.join(text)\n",
    "\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b0318-91d0-4686-924b-9f64cc0d64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583aaa1-fba7-43ba-984c-4112b17cbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e17a82-9c28-4616-b401-20e31d72938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"]=corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3f142-3c5f-49fa-a164-90909dd01847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"]=df[\"clean_text\"].str.replace(\"subject\",\"\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63103a3-4bac-4b1a-9589-a1c3f7fa5dc8",
   "metadata": {},
   "source": [
    "# splitting data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0df20-e14d-4ca5-bb30-9814de00b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.loc[:,\"clean_text\"].values\n",
    "y=df.loc[:,\"label_num\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98f92b-0afe-48d0-b79b-7f2afb8370f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d2401-3cd2-499b-af2d-9f152b0195e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bfec4-3edc-4764-8ec4-956c24eac7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00667f2-3cc2-4341-b049-b6b09599343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3932d823-1fc1-459f-b7b3-7859c2736391",
   "metadata": {},
   "source": [
    "# Classifiying using various classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443cac2-d186-44d6-a0f6-8816b5bb1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "import xgboost as xg\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b738f9a-b7b7-41bc-bd4d-cca252138693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5115fe-667c-42ba-bb0c-2d04589118ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model):\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    score=accuracy_score(y_test,y_pred)\n",
    "    print(f'accuracy score of {model} is :{score}')\n",
    "    print(f'{classification_report(y_test,y_pred)}')\n",
    "    mx=confusion_matrix(y_test,y_pred)\n",
    "    sns.heatmap(mx,annot=True, fmt='d', cmap='Blues', xticklabels=['Not spam', 'spam'], yticklabels=['Not spam', 'spam'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7306c89-3af6-4538-9fa1-cd7655c3038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb81f9b-8bbd-46f7-86e6-5ce007a5415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(DecisionTreeClassifier(max_depth=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d4326-34e5-48e4-923b-71f25c310dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4b9c4-1c74-4956-8241-7972e5bd0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(xg.XGBClassifier(learning_rate= 0.2, max_depth=7, n_estimators= 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1247e64-53eb-44c8-82e8-e51111634bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d7771-948a-4ce1-8693-cd2339c3cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098553c-df81-48ee-bbba-ffd266e2cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(GaussianNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b5088-37ff-4f8e-bff9-927fe9bba681",
   "metadata": {},
   "source": [
    "# Result and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2cead-84cc-46d0-91e5-7df3de2b8a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_num'].value_counts()/df['label_num'].count().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105ba11-e317-4583-a608-c65b2115e451",
   "metadata": {},
   "source": [
    "so we could see that our model has done better as it is better to use the model than saying that mail is not spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64250b24-c678-41e2-b325-27840a84d8be",
   "metadata": {},
   "source": [
    "we could see that `random forest` has better accuracy i.e of `97.64`%\n",
    "* Improvements can be done by tuning the hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
